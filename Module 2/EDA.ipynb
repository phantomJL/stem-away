{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading file\n",
    "one thing needs to pay attention is that reading csv file will change list type to string. Json file will not have this problem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic Title</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Author</th>\n",
       "      <th>Commenters</th>\n",
       "      <th>Leading Comment</th>\n",
       "      <th>Other Comments</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>About the Buying/Selling category</td>\n",
       "      <td>Buying/Selling</td>\n",
       "      <td>[]</td>\n",
       "      <td>system</td>\n",
       "      <td>[]</td>\n",
       "      <td>Debating a new ride? Ask all your buying and s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Car Salesperson Commissions</td>\n",
       "      <td>Buying/Selling</td>\n",
       "      <td>[]</td>\n",
       "      <td>wolyrobb</td>\n",
       "      <td>['wentwest', 'shadowfax', 'VOLVO-V70', 'Trieda...</td>\n",
       "      <td>I’ve been working with a particular salesperso...</td>\n",
       "      <td>['No one here can tell you what any dealers co...</td>\n",
       "      <td>12</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best used car to buy for long road trips?</td>\n",
       "      <td>Buying/Selling</td>\n",
       "      <td>['used-cars']</td>\n",
       "      <td>Whitey</td>\n",
       "      <td>['texases', 'VOLVO-V70', 'Marnet', 'lion9car',...</td>\n",
       "      <td>Hello! I am new to the site and am having a di...</td>\n",
       "      <td>['The answer to your question depends far more...</td>\n",
       "      <td>44</td>\n",
       "      <td>14.6k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Honda Element any good?</td>\n",
       "      <td>Buying/Selling</td>\n",
       "      <td>['honda', 'element']</td>\n",
       "      <td>texases</td>\n",
       "      <td>['VOLVO-V70', 'old_mopar_guy', 'lockstar', 'sh...</td>\n",
       "      <td>Are these any good and were they discontinued?...</td>\n",
       "      <td>['A simple Google search would have shown that...</td>\n",
       "      <td>24</td>\n",
       "      <td>1.2k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993 4Runner vs 2011 Mazda3 Hatch</td>\n",
       "      <td>Buying/Selling</td>\n",
       "      <td>['toyota', '4runner', 'buying', 'used-cars']</td>\n",
       "      <td>galant</td>\n",
       "      <td>['wolyrobb', 'Nevada_545', 'jordanethan609_175...</td>\n",
       "      <td>I’m conflicted between these two cars\\n4Runner...</td>\n",
       "      <td>['You are comparing apples to hamsters with th...</td>\n",
       "      <td>46</td>\n",
       "      <td>1.7k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Topic Title        Category  \\\n",
       "0          About the Buying/Selling category  Buying/Selling   \n",
       "1            New Car Salesperson Commissions  Buying/Selling   \n",
       "2  Best used car to buy for long road trips?  Buying/Selling   \n",
       "3                    Honda Element any good?  Buying/Selling   \n",
       "4          1993 4Runner vs 2011 Mazda3 Hatch  Buying/Selling   \n",
       "\n",
       "                                           Tags    Author  \\\n",
       "0                                            []    system   \n",
       "1                                            []  wolyrobb   \n",
       "2                                 ['used-cars']    Whitey   \n",
       "3                          ['honda', 'element']   texases   \n",
       "4  ['toyota', '4runner', 'buying', 'used-cars']    galant   \n",
       "\n",
       "                                          Commenters  \\\n",
       "0                                                 []   \n",
       "1  ['wentwest', 'shadowfax', 'VOLVO-V70', 'Trieda...   \n",
       "2  ['texases', 'VOLVO-V70', 'Marnet', 'lion9car',...   \n",
       "3  ['VOLVO-V70', 'old_mopar_guy', 'lockstar', 'sh...   \n",
       "4  ['wolyrobb', 'Nevada_545', 'jordanethan609_175...   \n",
       "\n",
       "                                     Leading Comment  \\\n",
       "0  Debating a new ride? Ask all your buying and s...   \n",
       "1  I’ve been working with a particular salesperso...   \n",
       "2  Hello! I am new to the site and am having a di...   \n",
       "3  Are these any good and were they discontinued?...   \n",
       "4  I’m conflicted between these two cars\\n4Runner...   \n",
       "\n",
       "                                      Other Comments Likes  Views  \n",
       "0                                                 []     1   2.2k  \n",
       "1  ['No one here can tell you what any dealers co...    12    559  \n",
       "2  ['The answer to your question depends far more...    44  14.6k  \n",
       "3  ['A simple Google search would have shown that...    24   1.2k  \n",
       "4  ['You are comparing apples to hamsters with th...    46   1.7k  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "\n",
    "train = pd.read_csv('combined_csv.csv')\n",
    "train = train.drop([\"Unnamed: 0\"], axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train =train[train.Category != ' 1990. My husband and I rented a spiffy new Cadillac in Indiana with plans to pick up my parents in Erie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic Title</th>\n",
       "      <th>Category</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Author</th>\n",
       "      <th>Commenters</th>\n",
       "      <th>Leading Comment</th>\n",
       "      <th>Other Comments</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>About the Buying/Selling category</td>\n",
       "      <td>Buying/Selling</td>\n",
       "      <td>[]</td>\n",
       "      <td>system</td>\n",
       "      <td>[]</td>\n",
       "      <td>Debating a new ride? Ask all your buying and s...</td>\n",
       "      <td>[[, ]]</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Car Salesperson Commissions</td>\n",
       "      <td>Buying/Selling</td>\n",
       "      <td>[]</td>\n",
       "      <td>wolyrobb</td>\n",
       "      <td>['wentwest', 'shadowfax', 'VOLVO-V70', 'Trieda...</td>\n",
       "      <td>I’ve been working with a particular salesperso...</td>\n",
       "      <td>[[, ', N, o,  , o, n, e,  , h, e, r, e,  , c, ...</td>\n",
       "      <td>12</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best used car to buy for long road trips?</td>\n",
       "      <td>Buying/Selling</td>\n",
       "      <td>['used-cars']</td>\n",
       "      <td>Whitey</td>\n",
       "      <td>['texases', 'VOLVO-V70', 'Marnet', 'lion9car',...</td>\n",
       "      <td>Hello! I am new to the site and am having a di...</td>\n",
       "      <td>[[, ', T, h, e,  , a, n, s, w, e, r,  , t, o, ...</td>\n",
       "      <td>44</td>\n",
       "      <td>14.6k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Honda Element any good?</td>\n",
       "      <td>Buying/Selling</td>\n",
       "      <td>['honda', 'element']</td>\n",
       "      <td>texases</td>\n",
       "      <td>['VOLVO-V70', 'old_mopar_guy', 'lockstar', 'sh...</td>\n",
       "      <td>Are these any good and were they discontinued?...</td>\n",
       "      <td>[[, ', A,  , s, i, m, p, l, e,  , G, o, o, g, ...</td>\n",
       "      <td>24</td>\n",
       "      <td>1.2k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1993 4Runner vs 2011 Mazda3 Hatch</td>\n",
       "      <td>Buying/Selling</td>\n",
       "      <td>['toyota', '4runner', 'buying', 'used-cars']</td>\n",
       "      <td>galant</td>\n",
       "      <td>['wolyrobb', 'Nevada_545', 'jordanethan609_175...</td>\n",
       "      <td>I’m conflicted between these two cars\\n4Runner...</td>\n",
       "      <td>[[, ', Y, o, u,  , a, r, e,  , c, o, m, p, a, ...</td>\n",
       "      <td>46</td>\n",
       "      <td>1.7k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Topic Title        Category  \\\n",
       "0          About the Buying/Selling category  Buying/Selling   \n",
       "1            New Car Salesperson Commissions  Buying/Selling   \n",
       "2  Best used car to buy for long road trips?  Buying/Selling   \n",
       "3                    Honda Element any good?  Buying/Selling   \n",
       "4          1993 4Runner vs 2011 Mazda3 Hatch  Buying/Selling   \n",
       "\n",
       "                                           Tags    Author  \\\n",
       "0                                            []    system   \n",
       "1                                            []  wolyrobb   \n",
       "2                                 ['used-cars']    Whitey   \n",
       "3                          ['honda', 'element']   texases   \n",
       "4  ['toyota', '4runner', 'buying', 'used-cars']    galant   \n",
       "\n",
       "                                          Commenters  \\\n",
       "0                                                 []   \n",
       "1  ['wentwest', 'shadowfax', 'VOLVO-V70', 'Trieda...   \n",
       "2  ['texases', 'VOLVO-V70', 'Marnet', 'lion9car',...   \n",
       "3  ['VOLVO-V70', 'old_mopar_guy', 'lockstar', 'sh...   \n",
       "4  ['wolyrobb', 'Nevada_545', 'jordanethan609_175...   \n",
       "\n",
       "                                     Leading Comment  \\\n",
       "0  Debating a new ride? Ask all your buying and s...   \n",
       "1  I’ve been working with a particular salesperso...   \n",
       "2  Hello! I am new to the site and am having a di...   \n",
       "3  Are these any good and were they discontinued?...   \n",
       "4  I’m conflicted between these two cars\\n4Runner...   \n",
       "\n",
       "                                      Other Comments Likes  Views  \n",
       "0                                             [[, ]]     1   2.2k  \n",
       "1  [[, ', N, o,  , o, n, e,  , h, e, r, e,  , c, ...    12    559  \n",
       "2  [[, ', T, h, e,  , a, n, s, w, e, r,  , t, o, ...    44  14.6k  \n",
       "3  [[, ', A,  , s, i, m, p, l, e,  , G, o, o, g, ...    24   1.2k  \n",
       "4  [[, ', Y, o, u,  , a, r, e,  , c, o, m, p, a, ...    46   1.7k  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_url(str):\n",
    "    pattern =  r\"/(http|https|ftp|ftps)\\:\\/\\/[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(\\/\\S*)?/\"\n",
    "    result = re.sub(pattern,\" \", str)\n",
    "    return result\n",
    "\n",
    "train[\"Other Comments\"] = train[\"Other Comments\"].apply(lambda x: list(map(replace_url, x)) )\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['Leading Comment'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean string by changing url link into a space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Leading Comment</th>\n",
       "      <th>lead_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Debating a new ride? Ask all your buying and s...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I’ve been working with a particular salesperso...</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello! I am new to the site and am having a di...</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are these any good and were they discontinued?...</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I’m conflicted between these two cars\\n4Runner...</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Leading Comment  lead_word_count\n",
       "0  Debating a new ride? Ask all your buying and s...               12\n",
       "1  I’ve been working with a particular salesperso...              152\n",
       "2  Hello! I am new to the site and am having a di...              130\n",
       "3  Are these any good and were they discontinued?...              192\n",
       "4  I’m conflicted between these two cars\\n4Runner...              183"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_analysis = pd.DataFrame()\n",
    "comment_analysis = pd.DataFrame()\n",
    "\n",
    "\n",
    "words_analysis['Leading Comment'] = train['Leading Comment']\n",
    "words_analysis[\"lead_word_count\"]= train['Leading Comment'].apply(lambda x: len(str(x).split(\" \")))\n",
    "comment_analysis['comment_count'] = len(train['Other Comments'])\n",
    "comment_analysis['comment_word_count'] = list(map(lambda x: len(''.join(x).split(\" \")),train['Other Comments']))\n",
    "\n",
    "\n",
    "words_analysis.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Leading Comment</th>\n",
       "      <th>lead_word_count</th>\n",
       "      <th>lead_char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Debating a new ride? Ask all your buying and s...</td>\n",
       "      <td>12</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I’ve been working with a particular salesperso...</td>\n",
       "      <td>152</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello! I am new to the site and am having a di...</td>\n",
       "      <td>130</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are these any good and were they discontinued?...</td>\n",
       "      <td>192</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I’m conflicted between these two cars\\n4Runner...</td>\n",
       "      <td>183</td>\n",
       "      <td>953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Leading Comment  lead_word_count  \\\n",
       "0  Debating a new ride? Ask all your buying and s...               12   \n",
       "1  I’ve been working with a particular salesperso...              152   \n",
       "2  Hello! I am new to the site and am having a di...              130   \n",
       "3  Are these any good and were they discontinued?...              192   \n",
       "4  I’m conflicted between these two cars\\n4Runner...              183   \n",
       "\n",
       "   lead_char_count  \n",
       "0               68  \n",
       "1              779  \n",
       "2              648  \n",
       "3             1000  \n",
       "4              953  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_analysis[\"lead_char_count\"] = train['Leading Comment'].str.len()\n",
    "comment_analysis[\"comment_char_count\"] = train['Other Comments'].apply(lambda x:len(''.join(x)))\n",
    "words_analysis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "necessary for the first time using nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jianglu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "stop[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Leading Comment</th>\n",
       "      <th>lead_word_count</th>\n",
       "      <th>lead_char_count</th>\n",
       "      <th>lead_stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Debating a new ride? Ask all your buying and s...</td>\n",
       "      <td>12</td>\n",
       "      <td>68</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I’ve been working with a particular salesperso...</td>\n",
       "      <td>152</td>\n",
       "      <td>779</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello! I am new to the site and am having a di...</td>\n",
       "      <td>130</td>\n",
       "      <td>648</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are these any good and were they discontinued?...</td>\n",
       "      <td>192</td>\n",
       "      <td>1000</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I’m conflicted between these two cars\\n4Runner...</td>\n",
       "      <td>183</td>\n",
       "      <td>953</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Leading Comment  lead_word_count  \\\n",
       "0  Debating a new ride? Ask all your buying and s...               12   \n",
       "1  I’ve been working with a particular salesperso...              152   \n",
       "2  Hello! I am new to the site and am having a di...              130   \n",
       "3  Are these any good and were they discontinued?...              192   \n",
       "4  I’m conflicted between these two cars\\n4Runner...              183   \n",
       "\n",
       "   lead_char_count  lead_stop_words  \n",
       "0               68                4  \n",
       "1              779               57  \n",
       "2              648               56  \n",
       "3             1000               56  \n",
       "4              953               76  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_analysis[\"lead_stop_words\"] = train['Leading Comment'].apply(lambda x: len([x for x in str(x).split() if x in stop]))\n",
    "comment_analysis[\"comment_stop_words\"] = train['Other Comments'].apply(lambda x: len([x for x in ''.join(x).split() if x in stop]))\n",
    "words_analysis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Leading Comment</th>\n",
       "      <th>Other Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>debating a new ride? ask all your buying and s...</td>\n",
       "      <td>[[, ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i’ve been working with a particular salesperso...</td>\n",
       "      <td>[[, ', n, o, , o, n, e, , h, e, r, e, , c, a, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hello! i am new to the site and am having a di...</td>\n",
       "      <td>[[, ', t, h, e, , a, n, s, w, e, r, , t, o, , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>are these any good and were they discontinued?...</td>\n",
       "      <td>[[, ', a, , s, i, m, p, l, e, , g, o, o, g, l,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i’m conflicted between these two cars 4runner ...</td>\n",
       "      <td>[[, ', y, o, u, , a, r, e, , c, o, m, p, a, r,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603</th>\n",
       "      <td>i purchased a pre-owned 2004 lexus es330 95k m...</td>\n",
       "      <td>[[, ', s, o, , y, o, u, , d, o, , h, a, v, e, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6604</th>\n",
       "      <td>i’m on my 3rd prius. i like it, but am thinkin...</td>\n",
       "      <td>[[, ', \\, n, \\, n, \\, n, , r, e, d, g, l, a, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6605</th>\n",
       "      <td>my 2009 hyundai santa fe won’t start. it start...</td>\n",
       "      <td>[[, ]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6606</th>\n",
       "      <td>outside temp stays at 75f although it is over ...</td>\n",
       "      <td>[[, ', i, , t, h, i, n, k, , t, h, i, s, , i, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6607</th>\n",
       "      <td>check engine light is on: code is p0008 recent...</td>\n",
       "      <td>[[, ]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Leading Comment  \\\n",
       "0     debating a new ride? ask all your buying and s...   \n",
       "1     i’ve been working with a particular salesperso...   \n",
       "2     hello! i am new to the site and am having a di...   \n",
       "3     are these any good and were they discontinued?...   \n",
       "4     i’m conflicted between these two cars 4runner ...   \n",
       "...                                                 ...   \n",
       "6603  i purchased a pre-owned 2004 lexus es330 95k m...   \n",
       "6604  i’m on my 3rd prius. i like it, but am thinkin...   \n",
       "6605  my 2009 hyundai santa fe won’t start. it start...   \n",
       "6606  outside temp stays at 75f although it is over ...   \n",
       "6607  check engine light is on: code is p0008 recent...   \n",
       "\n",
       "                                         Other Comments  \n",
       "0                                                [[, ]]  \n",
       "1     [[, ', n, o, , o, n, e, , h, e, r, e, , c, a, ...  \n",
       "2     [[, ', t, h, e, , a, n, s, w, e, r, , t, o, , ...  \n",
       "3     [[, ', a, , s, i, m, p, l, e, , g, o, o, g, l,...  \n",
       "4     [[, ', y, o, u, , a, r, e, , c, o, m, p, a, r,...  \n",
       "...                                                 ...  \n",
       "6603  [[, ', s, o, , y, o, u, , d, o, , h, a, v, e, ...  \n",
       "6604  [[, ', \\, n, \\, n, \\, n, , r, e, d, g, l, a, m...  \n",
       "6605                                             [[, ]]  \n",
       "6606  [[, ', i, , t, h, i, n, k, , t, h, i, s, , i, ...  \n",
       "6607                                             [[, ]]  \n",
       "\n",
       "[6600 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Leading Comment'] = train['Leading Comment'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
    "train['Other Comments'] = train['Other Comments'].apply(lambda z: list(map(lambda x: \" \".join(x.lower() for x in str(x).split()), z)))\n",
    "train[['Leading Comment','Other Comments']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove puctuation and stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    debating a new ride? ask all your buying and s...\n",
       "1    i’ve been working with a particular salesperso...\n",
       "2    hello! i am new to the site and am having a di...\n",
       "3    are these any good and were they discontinued?...\n",
       "4    i’m conflicted between these two cars 4runner ...\n",
       "Name: Leading Comment, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove puc\n",
    "train['Leading Comment'] = train['Leading Comment'].replace('[^\\w\\s]','')\n",
    "train[\"Leading Comment\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    debating new ride? ask buying selling question...\n",
       "1    i’ve working particular salesperson purchase n...\n",
       "2    hello! new site dilemma… good used car buy dis...\n",
       "3    good discontinued? still make 2021? would bett...\n",
       "4    i’m conflicted two cars 4runner $4700 (193,000...\n",
       "Name: Leading Comment, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove stop words\n",
    "train['Leading Comment'] = train['Leading Comment'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "train['Leading Comment'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove common word and rare word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car', 'would', 'fuel', 'gas', 'like', 'get', 'engine', 'one', 'new', 'i’m']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# common word\n",
    "freq1 = list(pd.Series(' '.join(train['Leading Comment']).split()).value_counts()[:10].index)\n",
    "freq1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['collapsing.',\n",
       " 'axleback',\n",
       " 'suing',\n",
       " '94,000',\n",
       " '(1986',\n",
       " 'eye-popping',\n",
       " '“pete',\n",
       " 'publicly',\n",
       " 'hse',\n",
       " '15.8']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rare word\n",
    "freq2 = list(pd.Series(' '.join(train['Leading Comment']).split()).value_counts()[-10:].index)\n",
    "freq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    debating ride? ask buying selling questions here.\n",
       "1    i’ve working particular salesperson purchase c...\n",
       "2    hello! site dilemma… good used buy distance dr...\n",
       "3    good discontinued? still make 2021? better pic...\n",
       "4    conflicted two cars 4runner $4700 (193,000) ma...\n",
       "Name: Leading Comment, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = freq1 + freq2\n",
    "train['Leading Comment']  = train['Leading Comment'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "train['Leading Comment'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check spelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     dealing ride? ask buying selling questions here.\n",
       "1    i’ve working particular salesperson purchase c...\n",
       "2    hello! site dilemma… good used buy distance dr...\n",
       "3    good discontinued? still make 2021? better pic...\n",
       "4    conflict two cars runner $4700 (193,000) madam...\n",
       "Name: Leading Comment, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "train['Leading Comment'][:5].apply(lambda x: str(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jianglu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenization\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['i', '’', 've', 'working', 'particular', 'salesperson', 'purchase', 'car', 'really', 'helpful', 'spent', 'time', 'select', 'correct', 'vehicle', 'ready', 'buy', 'i', '’', 've', 'tried', 'coming', 'dealership', 'couple', 'different', 'days', 'something', 'came', 'home', 'couldn', '’', 't', 'make', 'there', 'hard', 'find', 'time', 'afternoon', 'open', 'time', 'period', 'rare', 'could', 'go', 'make', 'purchase', 'salesperson', 'doesn', '’', 't', 'work', 'today', 'go', 'different', 'salesperson', 'making', 'sale', 'thinking', 'went', 'today', 'original', 'salesperson', 'who', 'put', 'time', 'lose', 'commission', '…', 'seems', 'disloyal', 'since', 'real', 'work', 'correct', 'today', '’', 's', 'salesperson', 'commission', 'thanks'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(train['Leading Comment'][1]).words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              debat ride? ask buy sell question here.\n",
       "1    i’v work particular salesperson purchas car. r...\n",
       "2    hello! site dilemma… good use buy distanc driv...\n",
       "3    good discontinued? still make 2021? better pic...\n",
       "4    conflict two car 4runner $4700 (193,000) mazda...\n",
       "Name: Leading Comment, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "st = PorterStemmer()\n",
    "train['Leading Comment'][:5].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/jianglu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lemmatization\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     debating ride? ask buying selling question here.\n",
       "1    i’ve working particular salesperson purchase c...\n",
       "2    hello! site dilemma… good used buy distance dr...\n",
       "3    good discontinued? still make 2021? better pic...\n",
       "4    conflicted two car 4runner $4700 (193,000) maz...\n",
       "Name: Leading Comment, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "train['Leading Comment'] = train['Leading Comment'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "train['Leading Comment'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Advance Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['i', '’']),\n",
       " WordList(['’', 've']),\n",
       " WordList(['ve', 'working']),\n",
       " WordList(['working', 'particular']),\n",
       " WordList(['particular', 'salesperson']),\n",
       " WordList(['salesperson', 'purchase']),\n",
       " WordList(['purchase', 'car']),\n",
       " WordList(['car', 'really']),\n",
       " WordList(['really', 'helpful']),\n",
       " WordList(['helpful', 'spent']),\n",
       " WordList(['spent', 'time']),\n",
       " WordList(['time', 'select']),\n",
       " WordList(['select', 'correct']),\n",
       " WordList(['correct', 'vehicle']),\n",
       " WordList(['vehicle', 'ready']),\n",
       " WordList(['ready', 'buy']),\n",
       " WordList(['buy', 'i']),\n",
       " WordList(['i', '’']),\n",
       " WordList(['’', 've']),\n",
       " WordList(['ve', 'tried']),\n",
       " WordList(['tried', 'coming']),\n",
       " WordList(['coming', 'dealership']),\n",
       " WordList(['dealership', 'couple']),\n",
       " WordList(['couple', 'different']),\n",
       " WordList(['different', 'days']),\n",
       " WordList(['days', 'something']),\n",
       " WordList(['something', 'came']),\n",
       " WordList(['came', 'home']),\n",
       " WordList(['home', 'couldn']),\n",
       " WordList(['couldn', '’']),\n",
       " WordList(['’', 't']),\n",
       " WordList(['t', 'make']),\n",
       " WordList(['make', 'there']),\n",
       " WordList(['there', 'hard']),\n",
       " WordList(['hard', 'find']),\n",
       " WordList(['find', 'time']),\n",
       " WordList(['time', 'afternoon']),\n",
       " WordList(['afternoon', 'open']),\n",
       " WordList(['open', 'time']),\n",
       " WordList(['time', 'period']),\n",
       " WordList(['period', 'rare']),\n",
       " WordList(['rare', 'could']),\n",
       " WordList(['could', 'go']),\n",
       " WordList(['go', 'make']),\n",
       " WordList(['make', 'purchase']),\n",
       " WordList(['purchase', 'salesperson']),\n",
       " WordList(['salesperson', 'doesn']),\n",
       " WordList(['doesn', '’']),\n",
       " WordList(['’', 't']),\n",
       " WordList(['t', 'work']),\n",
       " WordList(['work', 'today']),\n",
       " WordList(['today', 'go']),\n",
       " WordList(['go', 'different']),\n",
       " WordList(['different', 'salesperson']),\n",
       " WordList(['salesperson', 'making']),\n",
       " WordList(['making', 'sale']),\n",
       " WordList(['sale', 'thinking']),\n",
       " WordList(['thinking', 'went']),\n",
       " WordList(['went', 'today']),\n",
       " WordList(['today', 'original']),\n",
       " WordList(['original', 'salesperson']),\n",
       " WordList(['salesperson', 'who']),\n",
       " WordList(['who', 'put']),\n",
       " WordList(['put', 'time']),\n",
       " WordList(['time', 'lose']),\n",
       " WordList(['lose', 'commission']),\n",
       " WordList(['commission', '…']),\n",
       " WordList(['…', 'seems']),\n",
       " WordList(['seems', 'disloyal']),\n",
       " WordList(['disloyal', 'since']),\n",
       " WordList(['since', 'real']),\n",
       " WordList(['real', 'work']),\n",
       " WordList(['work', 'correct']),\n",
       " WordList(['correct', 'today']),\n",
       " WordList(['today', '’']),\n",
       " WordList(['’', 's']),\n",
       " WordList(['s', 'salesperson']),\n",
       " WordList(['salesperson', 'commission']),\n",
       " WordList(['commission', 'thanks'])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N-grams\n",
    "TextBlob(train['Leading Comment'][1]).ngrams(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>salesperson</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i’ve</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>different</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>time</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>make</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>go</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>today,</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>time.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hard</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>thinking</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>open</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(rare)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>doesn’t</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>time)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>afternoon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>disloyal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>since</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>car.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>purchase</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>coming</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>today’s</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>period</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>there.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tried</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>seems</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>correct</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>find</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>purchase.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ready</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>buy.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>commission</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>making</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>vehicle.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>particular</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>couple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>helpful</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>…</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>home</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>sale.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>could</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>really</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>couldn’t</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>correct?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>work.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>work</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>something</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>working</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>days,</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>thanks.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>came</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>select</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>commission?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>lose</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>(who</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>original</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>real</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>went</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>spent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>dealership</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>put</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          words  tf\n",
       "0   salesperson   5\n",
       "1          i’ve   2\n",
       "2     different   2\n",
       "3          time   2\n",
       "4          make   2\n",
       "5            go   2\n",
       "6        today,   2\n",
       "7         time.   1\n",
       "8          hard   1\n",
       "9      thinking   1\n",
       "10         open   1\n",
       "11       (rare)   1\n",
       "12      doesn’t   1\n",
       "13        time)   1\n",
       "14    afternoon   1\n",
       "15     disloyal   1\n",
       "16        since   1\n",
       "17         car.   1\n",
       "18     purchase   1\n",
       "19       coming   1\n",
       "20      today’s   1\n",
       "21       period   1\n",
       "22       there.   1\n",
       "23        tried   1\n",
       "24        seems   1\n",
       "25      correct   1\n",
       "26         find   1\n",
       "27    purchase.   1\n",
       "28        ready   1\n",
       "29         buy.   1\n",
       "30   commission   1\n",
       "31       making   1\n",
       "32     vehicle.   1\n",
       "33   particular   1\n",
       "34       couple   1\n",
       "35      helpful   1\n",
       "36            …   1\n",
       "37         home   1\n",
       "38        sale.   1\n",
       "39        could   1\n",
       "40       really   1\n",
       "41     couldn’t   1\n",
       "42     correct?   1\n",
       "43        work.   1\n",
       "44         work   1\n",
       "45    something   1\n",
       "46      working   1\n",
       "47        days,   1\n",
       "48      thanks.   1\n",
       "49         came   1\n",
       "50       select   1\n",
       "51  commission?   1\n",
       "52         lose   1\n",
       "53         (who   1\n",
       "54     original   1\n",
       "55         real   1\n",
       "56         went   1\n",
       "57        spent   1\n",
       "58   dealership   1\n",
       "59          put   1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Term frequency\n",
    "tf1 = (train['Leading Comment'][1:2]).apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0).reset_index()\n",
    "tf1.columns = ['words','tf']\n",
    "tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jianglu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/strings.py:2001: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "unbalanced parenthesis at position 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-cc0b37b210f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'words'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m       \u001b[0mtf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'idf'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Leading Comment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtf1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1999\u001b[0m                 )\n\u001b[1;32m   2000\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2001\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2002\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mcontains\u001b[0;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[1;32m   2822\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mforbid_nonstring_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bytes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2823\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2824\u001b[0;31m         result = str_contains(\n\u001b[0m\u001b[1;32m   2825\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2826\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/strings.py\u001b[0m in \u001b[0;36mstr_contains\u001b[0;34m(arr, pat, case, flags, na, regex)\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIGNORECASE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mregex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/re.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;34m\"Compile a regular expression pattern, returning a Pattern object.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpurge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/re.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0m_MAXCACHE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/sre_compile.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/sre_parse.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(str, flags, state)\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\")\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unbalanced parenthesis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mSRE_FLAG_DEBUG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: unbalanced parenthesis at position 4"
     ]
    }
   ],
   "source": [
    "# Inverse Document Frequency\n",
    "import numpy as np\n",
    "\n",
    "for i,word in enumerate(tf1['words']):\n",
    "      tf1.loc[i, 'idf'] = np.log(train.shape[0]/(len(train[train['Leading Comment'].str.contains(word)])))\n",
    "tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term Frequency – Inverse Document Frequency (TF-IDF)\n",
    "tf1['tfidf'] = tf1['tf'] * tf1['idf']\n",
    "tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',\n",
    "stop_words= 'english',ngram_range=(1,1))\n",
    "train_vect = tfidf.fit_transform(train['Leading Comment'])\n",
    "print(train_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',\n",
    "stop_words= 'english',ngram_range=(1,1))\n",
    "train_vect2 = tfidf.fit_transform(words_analysis['Leading Comment'])\n",
    "print(train_vect2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf2 = (words_analysis['Leading Comment'][1:2]).apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0).reset_index()\n",
    "tf2.columns = ['words','tf']\n",
    "tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i,word in enumerate(tf2['words']):\n",
    "      tf2.loc[i, 'idf'] = np.log(words_analysis.shape[0]/(len(words_analysis[words_analysis['Leading Comment'].str.contains(word)])))\n",
    "tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf2['tfidf'] = tf2['tf'] * tf2['idf']\n",
    "compare = pd.DataFrame({\"words\": tf1[\"words\"],\n",
    "                        \"tf1_result\": tf1['tfidf'],\n",
    "                        \"tf2_result\": tf2['tfidf']})\n",
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_analysis.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1,1),analyzer = \"word\")\n",
    "train_bow = bow.fit_transform(train['Leading Comment'])\n",
    "print(train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment Analysis\n",
    "train['Leading Comment'][:5].apply(lambda x: TextBlob(x).sentiment)\n",
    "train['sentiment'] = train['Leading Comment'].apply(lambda x: TextBlob(x).sentiment[0] )\n",
    "words_analysis['sentiment'] = train['sentiment']\n",
    "train[['Leading Comment','sentiment']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_input_file = 'glove.6B.100d.txt'\n",
    "word2vec_output_file = 'glove.6B.100d.txt.word2vec'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors # load the Stanford GloVe model\n",
    "filename = 'glove.6B.100d.txt.word2vec'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis for Natural Language Processing: A Complete Guide to Python Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "new= train['Leading Comment'].str.split()\n",
    "new=new.values.tolist()\n",
    "corpus=[word for i in new for word in i]\n",
    "\n",
    "from collections import defaultdict\n",
    "dic=defaultdict(int)\n",
    "for word in corpus:\n",
    "    if word in stop:\n",
    "        dic[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_ngram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(n, n)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) \n",
    "                  for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "top_n_bigrams=get_top_ngram(train['Leading Comment'],2)[:10]\n",
    "x,y=map(list,zip(*top_n_bigrams))\n",
    "sns.barplot(x=y,y=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tri_grams=get_top_ngram(train['Leading Comment'],n=3)\n",
    "x,y=map(list,zip(*top_tri_grams))\n",
    "sns.barplot(x=y,y=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling exploration with pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "def show_wordcloud(data):\n",
    "    wordcloud = WordCloud(\n",
    "        background_color='white',\n",
    "        stopwords=stopwords,\n",
    "        max_words=100,\n",
    "        max_font_size=30,\n",
    "        scale=3,\n",
    "        random_state=1)\n",
    "   \n",
    "    wordcloud=wordcloud.generate(str(data))\n",
    "\n",
    "    fig = plt.figure(1, figsize=(12, 12))\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.show()\n",
    "\n",
    "show_wordcloud(corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
